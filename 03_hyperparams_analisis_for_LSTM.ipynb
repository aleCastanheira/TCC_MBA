{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "15GsrRJBR-CAUAl0pgolhxhVcSbajPUv5",
      "authorship_tag": "ABX9TyNjoH4b4LknSh2GzslhU+cJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleCastanheira/TCC_MBA/blob/main/03_hyperparams_analisis_for_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "No setup deste notebook, importo as bibliotecas, defino as constantes e a configuração do pandas."
      ],
      "metadata": {
        "id": "gC5sBeU2XJW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVPfSFDN40Df",
        "outputId": "a3fbcbe2-c859-49e3-9472-24937b71a4d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import sample\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as md\n",
        "import plotly.graph_objects as go\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "yYkxKCCN79f9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Range de datas usadas para os rótulos dos gráficos no eixo X\n",
        "def get_date_strings(start_interval, end_interval):\n",
        "    timestamps = pd.date_range(start=start_interval, end=end_interval, periods=6, inclusive='both')\n",
        "    date_strings = [ts.strftime('%Y-%m-%d') for ts in timestamps]\n",
        "    return date_strings"
      ],
      "metadata": {
        "id": "fbKo4XRvY8t1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTANTES DO SCRIPT\n",
        "FILEPATH = \"/content/drive/MyDrive/TCC\"\n",
        "PROCESSED_METADATA_FILE = \"processed_metadata.csv\"\n",
        "PROCESSED_METADATA_OUTLIERS_FILE = \"processed_metadata_outliers.csv\"\n",
        "PROCESSED_METADATA_FILEPATH = f\"{FILEPATH}/{PROCESSED_METADATA_FILE}\"\n",
        "PROCESSED_METADATA_OUTLIERS_FILEPATH = f\"{FILEPATH}/{PROCESSED_METADATA_OUTLIERS_FILE}\"\n",
        "\n",
        "REF_DATE_KEY = \"reference_date\"\n",
        "TOTAL_SIZE = \"total_size\"\n",
        "TABLE_KEY = \"table\"\n",
        "\n",
        "TIMESERIES_COLUMNS = [REF_DATE_KEY, TOTAL_SIZE]\n",
        "\n",
        "# tabelas usadas para teste\n",
        "tab_list = [\n",
        "    'TAB000001', # crescimento constante, sem outliers aparente\n",
        "    # 'TAB000005', # mantém um padrão constante, não deve ter outliers\n",
        "    # 'TAB000008', # um pico grande no ano um\n",
        "]\n",
        "\n",
        "# intervalos de teste\n",
        "interval_list = [\n",
        "    # (\n",
        "    #     \"2021-01-01\",\n",
        "    #     \"2021-06-30\",\n",
        "    #     get_date_strings(\"2021-01-01\", \"2021-06-30\")\n",
        "    # ), #6 meses\n",
        "    # (\n",
        "    #     \"2021-01-01\",\n",
        "    #     \"2021-12-31\",\n",
        "    #     get_date_strings(\"2021-01-01\", \"2021-12-31\")\n",
        "    # ), #1 ano\n",
        "    (\n",
        "        \"2021-01-01\",\n",
        "        \"2022-12-31\",\n",
        "        get_date_strings(\"2021-01-01\", \"2022-12-31\")\n",
        "    ), #2 anos\n",
        "]\n",
        "\n",
        "# arquivos de teste\n",
        "metadata_files = [\n",
        "    # PROCESSED_METADATA_FILEPATH,\n",
        "    PROCESSED_METADATA_OUTLIERS_FILEPATH\n",
        "]\n",
        "\n",
        "# Aqui é aonde customizo as execuções, para avaliar diferentes períodos temporais\n",
        "# TABLE_FOR_TEST_01 = tab_list[0]\n",
        "# INTERVAL_FOR_TEST_01 = interval_list[0]\n",
        "# FILEPATH_FOR_TEST_01 = metadata_files[1]\n",
        "\n",
        "# date_strings = interval_list[0][2]\n",
        "\n",
        "# Populo as datas de referência de acordo com o periodo escolhido\n",
        "# START_DATE_INTERVAL = INTERVAL_FOR_TEST_01[0]\n",
        "# END_DATE_INTERVAL = INTERVAL_FOR_TEST_01[1]\n"
      ],
      "metadata": {
        "id": "4nAOOQ5c_EQm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparâmetros"
      ],
      "metadata": {
        "id": "7IgDtmjmO7km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM params\n",
        "network_units_list = [\n",
        "    # 64,\n",
        "    128,\n",
        "    # 256,\n",
        "]\n",
        "\n",
        "loss_list = [\n",
        "    # \"mae\",\n",
        "    \"huber\",\n",
        "    \"mse\",\n",
        "]\n",
        "\n",
        "optimizer_list = [\n",
        "    \"adam\",\n",
        "    # \"nadam\",\n",
        "    \"rmsprop\",\n",
        "]\n",
        "\n",
        "dropout_list = [\n",
        "    0.2,\n",
        "    0.4,\n",
        "]\n",
        "\n",
        "TIME_STEPS = 15\n",
        "qtd_epochs = 100\n",
        "batch_size = 15\n",
        "train_percentage = 0.7\n",
        "\n",
        "hyperparams_combination_list = []\n",
        "for network_unit in network_units_list:\n",
        "    for loss in loss_list:\n",
        "        for optimizer in optimizer_list:\n",
        "            for dropout in dropout_list:\n",
        "                hyperparams_combination_list.append({\n",
        "                    \"network_units\": network_unit,\n",
        "                    \"loss\": loss,\n",
        "                    \"optimizer\": optimizer,\n",
        "                    \"dropout_rate\": dropout,\n",
        "                })\n",
        "\n",
        "tunning_tests = []\n",
        "for tab in tab_list:\n",
        "    for interval in interval_list:\n",
        "        for filepath in metadata_files:\n",
        "            tunning_tests.append({\n",
        "                \"table_for_test\": tab,\n",
        "                \"interval_for_test\": interval,\n",
        "                \"filepath_for_test\": filepath,\n",
        "                \"hyperparameters\": hyperparams_combination_list,\n",
        "            })"
      ],
      "metadata": {
        "id": "5yoq7j8ZO95q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(filepath):\n",
        "    df = pd.read_csv(filepath, parse_dates=False)\n",
        "    return df"
      ],
      "metadata": {
        "id": "2ZcphA1h_F6j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultado final"
      ],
      "metadata": {
        "id": "3X7iPe31Zd9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REF_DATE_KEY = \"reference_date\"\n",
        "TOTAL_SIZE = \"total_size\"\n",
        "outliers_found = []\n",
        "\n",
        "def add_outliers_found(method, total_outliers, percentage):\n",
        "        global outliers_found\n",
        "        item = {\n",
        "            \"method\": method,\n",
        "            \"total_outliers\": total_outliers,\n",
        "            \"percentage\": \"{:.2f}%\".format(percentage)\n",
        "        }\n",
        "        outliers_found.append(item)\n",
        "\n",
        "\n",
        "# Função para fazer a plotagem do gráfico\n",
        "def plot_graph(df, outliers_df=None, method=None, date_strings=[]):\n",
        "    test_choosen = 1\n",
        "    plt.clf()\n",
        "    plt.locator_params(axis=\"x\", nbins=6)\n",
        "\n",
        "    plt.plot(df[REF_DATE_KEY], df[TOTAL_SIZE], label='Série temporal')\n",
        "\n",
        "    if outliers_df is not None:\n",
        "        plt.scatter(\n",
        "            outliers_df[REF_DATE_KEY],\n",
        "            outliers_df[TOTAL_SIZE],\n",
        "            color='red',\n",
        "            label='Anomalias detectadas'\n",
        "        )\n",
        "\n",
        "    plt.ylabel(\"Tamanho dos arquivos (KBs)\")\n",
        "    plt.xticks(date_strings, rotation=10)\n",
        "\n",
        "    plt.grid(True)\n",
        "    if method:\n",
        "        plt.title(f\"Anomalias encontradas usando o método '{method}'\", fontsize=10)\n",
        "    else:\n",
        "        plt.title(\"Dados presentes em uma tabela de Data Lake\", fontsize=14)\n",
        "\n",
        "    if outliers_df is not None:\n",
        "        total_outliers = len(outliers_df)\n",
        "        outlier_percent = (total_outliers / len(df)) * 100\n",
        "        add_outliers_found(method, total_outliers, outlier_percent)\n",
        "        img_name = f\"{FILEPATH}/imgs/TEST{test_choosen+1}/LSTM/{method}.png\".replace(\" \", \"_\")\n",
        "        plt.savefig(img_name)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def prepare_data(df, params):\n",
        "    # Filtrando para trazer apenas uma tabela\n",
        "    START_DATE_INTERVAL = params[\"interval_for_test\"][0]\n",
        "    END_DATE_INTERVAL = params[\"interval_for_test\"][1]\n",
        "\n",
        "    df = df[df[TABLE_KEY] == params[\"table_for_test\"]].copy()\n",
        "    df = df[(df[REF_DATE_KEY] >= START_DATE_INTERVAL) & (df[REF_DATE_KEY] <= END_DATE_INTERVAL)]\n",
        "    df[REF_DATE_KEY].min(), df[REF_DATE_KEY].max()\n",
        "    df[TOTAL_SIZE].astype('Int64')\n",
        "    df[REF_DATE_KEY] = pd.to_datetime(df[REF_DATE_KEY])\n",
        "\n",
        "    # Deixando apenas as colunas necessárias para a análise de séries temporais\n",
        "    df = df[TIMESERIES_COLUMNS].copy()\n",
        "    df = df.sort_values(by=REF_DATE_KEY)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_sequences(X, y, time_steps=TIME_STEPS):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X)-time_steps):\n",
        "        Xs.append(X.iloc[i:(i+time_steps)].values)\n",
        "        ys.append(y.iloc[i+time_steps])\n",
        "\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "\n",
        "def get_model(X_train, hyperparams):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(hyperparams[\"network_units\"], input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dropout(rate=hyperparams[\"dropout_rate\"]))\n",
        "    model.add(RepeatVector(X_train.shape[1]))\n",
        "    model.add(LSTM(hyperparams[\"network_units\"], return_sequences=True))\n",
        "    model.add(Dropout(rate=hyperparams[\"dropout_rate\"]))\n",
        "    model.add(TimeDistributed(Dense(X_train.shape[2])))\n",
        "    model.compile(optimizer=hyperparams[\"optimizer\"], loss=hyperparams[\"loss\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "def apply_scaler(train, test):\n",
        "    scaler = StandardScaler()\n",
        "    scaler = scaler.fit(train[[TOTAL_SIZE]])\n",
        "\n",
        "    train[TOTAL_SIZE] = scaler.transform(train[[TOTAL_SIZE]])\n",
        "    test[TOTAL_SIZE] = scaler.transform(test[[TOTAL_SIZE]])\n",
        "    return train, test\n",
        "\n",
        "\n",
        "def split_train_test_data(data):\n",
        "    df = data.copy()\n",
        "    train_size = int(len(df) * train_percentage)\n",
        "    test_size = len(df) - train_size\n",
        "    train, test = df[:train_size], df[train_size:]\n",
        "    return apply_scaler(train, test)\n",
        "\n",
        "\n",
        "def execute_from_params(params, hyperparams, plot_graps = False):\n",
        "    report = {}\n",
        "    data = get_data(params[\"filepath_for_test\"])\n",
        "    data = prepare_data(data, params)\n",
        "    train, test = split_train_test_data(data)\n",
        "\n",
        "    X_train, y_train = create_sequences(train[[TOTAL_SIZE]], train[TOTAL_SIZE])\n",
        "    X_test, y_test = create_sequences(test[[TOTAL_SIZE]], test[TOTAL_SIZE])\n",
        "    # print(f'Training shape: {X_train.shape}')\n",
        "    # print(f'Testing shape: {X_test.shape}')\n",
        "    model = get_model(X_train, hyperparams)\n",
        "    # print(model.summary())\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=qtd_epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[\n",
        "            keras.callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=3,\n",
        "                mode='min'\n",
        "            )\n",
        "        ],\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # print(model.evaluate(X_test, y_test))\n",
        "\n",
        "    X_train_pred = model.predict(X_train, verbose=0)\n",
        "    train_mae_loss = np.mean(np.abs(X_train_pred - X_train), axis=1)\n",
        "    plt.hist(train_mae_loss, bins=50)\n",
        "    plt.xlabel('Train MAE loss')\n",
        "    plt.ylabel('Number of Samples');\n",
        "\n",
        "    X_test_pred = model.predict(X_test, verbose=0)\n",
        "    test_mae_loss = np.mean(np.abs(X_test_pred-X_test), axis=1)\n",
        "\n",
        "    plt.hist(test_mae_loss, bins=50)\n",
        "    plt.xlabel('Test MAE loss')\n",
        "    plt.ylabel('Number of samples');\n",
        "\n",
        "    threshold = np.max(train_mae_loss)\n",
        "\n",
        "    X_test_pred = model.predict(X_test, verbose=0)\n",
        "    test_mae_loss = np.mean(np.abs(X_test_pred-X_test), axis=1)\n",
        "\n",
        "    test_score_df = pd.DataFrame(test[TIME_STEPS:])\n",
        "    test_score_df['loss'] = test_mae_loss\n",
        "    test_score_df['threshold'] = threshold\n",
        "    test_score_df['anomaly'] = test_score_df['loss'] > test_score_df['threshold']\n",
        "    test_score_df[TOTAL_SIZE] = test[TIME_STEPS:][TOTAL_SIZE]\n",
        "    anomalies = test_score_df.loc[test_score_df['anomaly'] == True]\n",
        "    outliers_total = len(anomalies.index)\n",
        "\n",
        "    test_score_df = pd.DataFrame(test[TIME_STEPS:])\n",
        "    test_score_df['loss'] = test_mae_loss\n",
        "    test_score_df['threshold'] = threshold\n",
        "    test_score_df['anomaly'] = test_score_df['loss'] > test_score_df['threshold']\n",
        "    test_score_df['Close'] = test[TIME_STEPS:][TOTAL_SIZE]\n",
        "\n",
        "    outlier_percent = (outliers_total / len(data.index)) * 100\n",
        "\n",
        "    report[\"hyperparams\"] = hyperparams\n",
        "    report[\"outliers_total\"] = outliers_total\n",
        "    report[\"outlier_percent\"] = outlier_percent\n",
        "    report[\"error_threshold\"] = threshold\n",
        "    report[\"model\"] = model\n",
        "\n",
        "    method = \"LSTM\"\n",
        "\n",
        "    if plot_graps:\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Scatter(x=df[REF_DATE_KEY], y=df[TOTAL_SIZE], name='Tamanho total de arquivos'))\n",
        "        fig.update_layout(showlegend=True, title='Tamanho total de arquivos entre 2020 e 2022')\n",
        "        fig.show()\n",
        "\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Scatter(x=test_score_df[REF_DATE_KEY], y=test_score_df['loss'], name='Test loss'))\n",
        "        fig.add_trace(go.Scatter(x=test_score_df[REF_DATE_KEY], y=test_score_df['threshold'], name='Threshold'))\n",
        "        fig.update_layout(showlegend=True, title='Test loss vs. Threshold')\n",
        "        fig.show()\n",
        "\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(go.Scatter(x=test_score_df[REF_DATE_KEY], y=test_score_df[TOTAL_SIZE], name='Observations'))\n",
        "        fig.add_trace(go.Scatter(x=anomalies[REF_DATE_KEY], y=anomalies[TOTAL_SIZE], mode='markers', name='Anomaly'))\n",
        "        fig.update_layout(showlegend=True, title='Detected anomalies')\n",
        "        fig.show()\n",
        "    return report\n",
        "\n",
        "def execute_tunning(tunning_tests):\n",
        "    report_tunning_list = []\n",
        "    for tunning_params in tunning_tests:\n",
        "        tunning_test = {}\n",
        "        tunning_test[\"table_for_test\"] = tunning_params[\"table_for_test\"]\n",
        "        tunning_test[\"interval_for_test\"] = tunning_params[\"interval_for_test\"]\n",
        "        tunning_test[\"tests\"] = []\n",
        "        for hyperparams in tunning_params[\"hyperparameters\"]:\n",
        "            test = {}\n",
        "            test[\"network_units\"] = hyperparams[\"network_units\"]\n",
        "            test[\"dropout_rate\"] = hyperparams[\"dropout_rate\"]\n",
        "            test[\"optimizer\"] = hyperparams[\"optimizer\"]\n",
        "            test[\"loss\"] = hyperparams[\"loss\"]\n",
        "\n",
        "            report = execute_from_params(tunning_params, hyperparams)\n",
        "\n",
        "            # só adiciono os casos que encontraram outliers\n",
        "            if report[\"outliers_total\"] > 0:\n",
        "                test[\"execution\"] = report\n",
        "                tunning_test[\"tests\"].append(test)\n",
        "\n",
        "        report_tunning_list.append(tunning_test)\n",
        "\n",
        "    return report_tunning_list\n",
        "\n",
        "report_tunning_list = execute_tunning(tunning_tests)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5f32HvVSdMgd",
        "outputId": "e23e7385-9c63-4bbc-f53c-427241121dbe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 0.2222 - val_loss: 0.1777\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0292 - val_loss: 0.1006\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.0300 - val_loss: 0.3003\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0460 - val_loss: 0.1020\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0320 - val_loss: 0.2090\n",
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 62ms/step - loss: 0.2494 - val_loss: 0.1832\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0341 - val_loss: 0.2764\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0448 - val_loss: 0.1914\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0382 - val_loss: 0.1723\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0345 - val_loss: 0.1920\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0317 - val_loss: 0.2122\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0298 - val_loss: 0.1615\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0216 - val_loss: 0.1346\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0167 - val_loss: 0.0911\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0146 - val_loss: 0.1192\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0159 - val_loss: 0.0662\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0141 - val_loss: 0.0891\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0196 - val_loss: 0.1534\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0235 - val_loss: 0.0855\n",
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - loss: 0.1440 - val_loss: 0.0913\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.0466 - val_loss: 0.0549\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0413 - val_loss: 0.0433\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0291 - val_loss: 0.0396\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0284 - val_loss: 0.0270\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0289 - val_loss: 0.0224\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0264 - val_loss: 0.0258\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0243 - val_loss: 0.0486\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0271 - val_loss: 0.0156\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0167 - val_loss: 0.0140\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.0190 - val_loss: 0.0205\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0207 - val_loss: 0.0347\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.0184 - val_loss: 0.0119\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0152 - val_loss: 0.0121\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0184 - val_loss: 0.0226\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0181 - val_loss: 0.0094\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - loss: 0.0128 - val_loss: 0.0091\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0164 - val_loss: 0.0125\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0133 - val_loss: 0.0088\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0140 - val_loss: 0.0153\n",
            "Epoch 21/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0161 - val_loss: 0.0082\n",
            "Epoch 22/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0150 - val_loss: 0.0087\n",
            "Epoch 23/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0140 - val_loss: 0.0154\n",
            "Epoch 24/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0169 - val_loss: 0.0084\n",
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - loss: 0.1742 - val_loss: 0.0960\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0528 - val_loss: 0.1236\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0591 - val_loss: 0.0440\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0319 - val_loss: 0.0377\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0371 - val_loss: 0.0295\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0321 - val_loss: 0.0259\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0308 - val_loss: 0.0254\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0275 - val_loss: 0.0197\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0278 - val_loss: 0.0181\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0243 - val_loss: 0.0163\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0230 - val_loss: 0.0182\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0241 - val_loss: 0.0159\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0246 - val_loss: 0.0159\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0245 - val_loss: 0.0142\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0194 - val_loss: 0.0273\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0239 - val_loss: 0.0177\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0247 - val_loss: 0.0096\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0184 - val_loss: 0.0107\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0225 - val_loss: 0.0198\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0202 - val_loss: 0.0193\n",
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.4677 - val_loss: 0.3265\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0560 - val_loss: 0.2962\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0555 - val_loss: 0.5671\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0755 - val_loss: 0.1748\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0515 - val_loss: 0.3023\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0638 - val_loss: 0.4714\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0688 - val_loss: 0.3030\n",
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.5491 - val_loss: 0.3579\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.0668 - val_loss: 0.3337\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0830 - val_loss: 0.6751\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.1056 - val_loss: 0.1702\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0615 - val_loss: 0.6356\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0906 - val_loss: 0.2595\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0609 - val_loss: 0.4903\n",
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 0.3767 - val_loss: 0.1984\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0872 - val_loss: 0.1110\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0722 - val_loss: 0.0835\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0666 - val_loss: 0.0697\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0620 - val_loss: 0.0522\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0592 - val_loss: 0.0541\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0513 - val_loss: 0.0386\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0616 - val_loss: 0.0884\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0650 - val_loss: 0.0449\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0459 - val_loss: 0.0308\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0431 - val_loss: 0.0287\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0417 - val_loss: 0.0619\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0486 - val_loss: 0.0285\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0349 - val_loss: 0.0206\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0404 - val_loss: 0.0344\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0399 - val_loss: 0.0176\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0361 - val_loss: 0.0205\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0315 - val_loss: 0.0175\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0348 - val_loss: 0.0240\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0396 - val_loss: 0.0154\n",
            "Epoch 21/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0231 - val_loss: 0.0487\n",
            "Epoch 22/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0345 - val_loss: 0.0196\n",
            "Epoch 23/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0330 - val_loss: 0.0212\n",
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.3748 - val_loss: 0.1936\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1254 - val_loss: 0.1094\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0730 - val_loss: 0.0855\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0810 - val_loss: 0.0839\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0740 - val_loss: 0.0546\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0614 - val_loss: 0.0568\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0563 - val_loss: 0.0394\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0490 - val_loss: 0.0451\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0460 - val_loss: 0.0342\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0439 - val_loss: 0.0292\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0459 - val_loss: 0.0863\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0539 - val_loss: 0.0296\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0368 - val_loss: 0.0334\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report_tunning_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4gBFhePBMqZ",
        "outputId": "daa0c46f-d4a1-4dda-fd81-3ad470613471"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'table_for_test': 'TAB000001',\n",
              "  'interval_for_test': ('2021-01-01',\n",
              "   '2022-12-31',\n",
              "   ['2021-01-01',\n",
              "    '2021-05-26',\n",
              "    '2021-10-19',\n",
              "    '2022-03-14',\n",
              "    '2022-08-07',\n",
              "    '2022-12-31']),\n",
              "  'tests': [{'network_units': 128,\n",
              "    'dropout_rate': 0.2,\n",
              "    'optimizer': 'adam',\n",
              "    'loss': 'huber',\n",
              "    'execution': {'hyperparams': {'network_units': 128,\n",
              "      'loss': 'huber',\n",
              "      'optimizer': 'adam',\n",
              "      'dropout_rate': 0.2},\n",
              "     'outliers_total': 188,\n",
              "     'outlier_percent': 25.753424657534246,\n",
              "     'error_threshold': 0.6763761586823591,\n",
              "     'model': <Sequential name=sequential, built=True>}},\n",
              "   {'network_units': 128,\n",
              "    'dropout_rate': 0.4,\n",
              "    'optimizer': 'adam',\n",
              "    'loss': 'huber',\n",
              "    'execution': {'hyperparams': {'network_units': 128,\n",
              "      'loss': 'huber',\n",
              "      'optimizer': 'adam',\n",
              "      'dropout_rate': 0.4},\n",
              "     'outliers_total': 205,\n",
              "     'outlier_percent': 28.08219178082192,\n",
              "     'error_threshold': 0.38710748224243824,\n",
              "     'model': <Sequential name=sequential_1, built=True>}},\n",
              "   {'network_units': 128,\n",
              "    'dropout_rate': 0.2,\n",
              "    'optimizer': 'rmsprop',\n",
              "    'loss': 'huber',\n",
              "    'execution': {'hyperparams': {'network_units': 128,\n",
              "      'loss': 'huber',\n",
              "      'optimizer': 'rmsprop',\n",
              "      'dropout_rate': 0.2},\n",
              "     'outliers_total': 45,\n",
              "     'outlier_percent': 6.164383561643835,\n",
              "     'error_threshold': 0.29719763631689644,\n",
              "     'model': <Sequential name=sequential_2, built=True>}},\n",
              "   {'network_units': 128,\n",
              "    'dropout_rate': 0.4,\n",
              "    'optimizer': 'rmsprop',\n",
              "    'loss': 'huber',\n",
              "    'execution': {'hyperparams': {'network_units': 128,\n",
              "      'loss': 'huber',\n",
              "      'optimizer': 'rmsprop',\n",
              "      'dropout_rate': 0.4},\n",
              "     'outliers_total': 43,\n",
              "     'outlier_percent': 5.89041095890411,\n",
              "     'error_threshold': 0.375681403663069,\n",
              "     'model': <Sequential name=sequential_3, built=True>}},\n",
              "   {'network_units': 128,\n",
              "    'dropout_rate': 0.2,\n",
              "    'optimizer': 'adam',\n",
              "    'loss': 'mse',\n",
              "    'execution': {'hyperparams': {'network_units': 128,\n",
              "      'loss': 'mse',\n",
              "      'optimizer': 'adam',\n",
              "      'dropout_rate': 0.2},\n",
              "     'outliers_total': 188,\n",
              "     'outlier_percent': 25.753424657534246,\n",
              "     'error_threshold': 0.5695087618508466,\n",
              "     'model': <Sequential name=sequential_4, built=True>}},\n",
              "   {'network_units': 128,\n",
              "    'dropout_rate': 0.4,\n",
              "    'optimizer': 'adam',\n",
              "    'loss': 'mse',\n",
              "    'execution': {'hyperparams': {'network_units': 128,\n",
              "      'loss': 'mse',\n",
              "      'optimizer': 'adam',\n",
              "      'dropout_rate': 0.4},\n",
              "     'outliers_total': 186,\n",
              "     'outlier_percent': 25.47945205479452,\n",
              "     'error_threshold': 0.7473632878937849,\n",
              "     'model': <Sequential name=sequential_5, built=True>}},\n",
              "   {'network_units': 128,\n",
              "    'dropout_rate': 0.2,\n",
              "    'optimizer': 'rmsprop',\n",
              "    'loss': 'mse',\n",
              "    'execution': {'hyperparams': {'network_units': 128,\n",
              "      'loss': 'mse',\n",
              "      'optimizer': 'rmsprop',\n",
              "      'dropout_rate': 0.2},\n",
              "     'outliers_total': 101,\n",
              "     'outlier_percent': 13.835616438356164,\n",
              "     'error_threshold': 0.2900980365512215,\n",
              "     'model': <Sequential name=sequential_6, built=True>}}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_tunning_reports(report_list):\n",
        "    test_number = 0\n",
        "\n",
        "    for report in report_list:\n",
        "        test_number = test_number + 1\n",
        "        table = report[\"table_for_test\"]\n",
        "        interval = report[\"interval_for_test\"][:-1]\n",
        "        print(f\"TESTE 0{test_number}\")\n",
        "        print(\"\\n\")\n",
        "        print(f\"table = {table}\")\n",
        "        print(f\"interval = {interval}\")\n",
        "        for test in report[\"tests\"]:\n",
        "            print(\"\\n\")\n",
        "            print(\"----------\")\n",
        "            print(\"\\n\")\n",
        "            print(f\"network_units: {test['network_units']}\")\n",
        "            print(f\"dropout_rate: {test['dropout_rate']}\")\n",
        "            print(f\"optimizer: {test['optimizer']}\")\n",
        "            print(f\"loss: {test['loss']}\")\n",
        "\n",
        "            outliers_total = test[\"execution\"]['outliers_total']\n",
        "            outlier_percent = test[\"execution\"]['outlier_percent']\n",
        "            error_threshold = test[\"execution\"]['error_threshold']\n",
        "            print(f\"outliers_total: {outliers_total}\")\n",
        "            print(f\"outlier_percent: {outlier_percent}\")\n",
        "            print(f\"error_threshold: {error_threshold}\")\n",
        "            # print(test[\"execution\"]['model'].summary())\n",
        "\n",
        "        print(\"-----------------------------------------------\")\n",
        "\n",
        "print_tunning_reports(report_tunning_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUIyiUR9_nOT",
        "outputId": "111e50f4-7580-4444-d722-08ba733d9806"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TESTE 01\n",
            "\n",
            "\n",
            "table = TAB000001\n",
            "interval = ('2021-01-01', '2022-12-31')\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "network_units: 128\n",
            "dropout_rate: 0.2\n",
            "optimizer: adam\n",
            "loss: huber\n",
            "outliers_total: 188\n",
            "outlier_percent: 25.753424657534246\n",
            "error_threshold: 0.6763761586823591\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "network_units: 128\n",
            "dropout_rate: 0.4\n",
            "optimizer: adam\n",
            "loss: huber\n",
            "outliers_total: 205\n",
            "outlier_percent: 28.08219178082192\n",
            "error_threshold: 0.38710748224243824\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "network_units: 128\n",
            "dropout_rate: 0.2\n",
            "optimizer: rmsprop\n",
            "loss: huber\n",
            "outliers_total: 45\n",
            "outlier_percent: 6.164383561643835\n",
            "error_threshold: 0.29719763631689644\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "network_units: 128\n",
            "dropout_rate: 0.4\n",
            "optimizer: rmsprop\n",
            "loss: huber\n",
            "outliers_total: 43\n",
            "outlier_percent: 5.89041095890411\n",
            "error_threshold: 0.375681403663069\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "network_units: 128\n",
            "dropout_rate: 0.2\n",
            "optimizer: adam\n",
            "loss: mse\n",
            "outliers_total: 188\n",
            "outlier_percent: 25.753424657534246\n",
            "error_threshold: 0.5695087618508466\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "network_units: 128\n",
            "dropout_rate: 0.4\n",
            "optimizer: adam\n",
            "loss: mse\n",
            "outliers_total: 186\n",
            "outlier_percent: 25.47945205479452\n",
            "error_threshold: 0.7473632878937849\n",
            "\n",
            "\n",
            "----------\n",
            "\n",
            "\n",
            "network_units: 128\n",
            "dropout_rate: 0.2\n",
            "optimizer: rmsprop\n",
            "loss: mse\n",
            "outliers_total: 101\n",
            "outlier_percent: 13.835616438356164\n",
            "error_threshold: 0.2900980365512215\n",
            "-----------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}